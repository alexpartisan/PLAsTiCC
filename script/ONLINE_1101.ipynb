{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature hostgal_specz is removed\n",
      "Dimension of merge data for MJD relevant data and META data  (1421705, 17)\n",
      "Number of objects in galaxy : 2325\n",
      "Number of objects out of galaxy : 5523\n",
      "Just to check, sum of objects : 7848\n",
      "Total number should be 7848\n",
      "Dimension of merge data for that in galaxy and that out of galaxy  (400574, 17) (1021131, 17)\n",
      "Dimension of aggregated data on flux features (7848, 18)\n",
      "Dimension of merge data for Object relevant data and META data (7848, 30)\n",
      "Number of objects in galaxy : 2325\n",
      "Number of objects out of galaxy : 5523\n",
      "Just to check, sum of objects : 7848\n",
      "Total number should be 7848\n",
      "Dimension of merge data for that in galaxy and that out of galaxy  (2325, 30) (5523, 30)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-ae6cab2ea8f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'object_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m     \u001b[0mdf_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mfillna\u001b[1;34m(self, value, method, axis, inplace, limit, downcast, **kwargs)\u001b[0m\n\u001b[0;32m   3788\u001b[0m                      \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3789\u001b[0m                                   \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3790\u001b[1;33m                                   downcast=downcast, **kwargs)\n\u001b[0m\u001b[0;32m   3791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mfillna\u001b[1;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[0;32m   5419\u001b[0m                         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5420\u001b[0m                     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5421\u001b[1;33m                     \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdowncast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdowncast\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5422\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mfillna\u001b[1;34m(self, value, method, axis, inplace, limit, downcast, **kwargs)\u001b[0m\n\u001b[0;32m   3423\u001b[0m                                           \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3424\u001b[0m                                           \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdowncast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdowncast\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3425\u001b[1;33m                                           **kwargs)\n\u001b[0m\u001b[0;32m   3426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3427\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mfillna\u001b[1;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[0;32m   5432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5435\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5436\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_update_inplace\u001b[1;34m(self, result, **kwargs)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;31m# we want to call the generic version and not the IndexOpsMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_update_inplace\u001b[1;34m(self, result, verify_is_copy)\u001b[0m\n\u001b[0;32m   3185\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3186\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3187\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverify_is_copy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_is_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0madd_prefix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_maybe_update_cacher\u001b[1;34m(self, clear, verify_is_copy)\u001b[0m\n\u001b[0;32m   2570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mverify_is_copy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2572\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_setitem_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'referant'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2574\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclear\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_check_setitem_copy\u001b[1;34m(self, stacklevel, t, force)\u001b[0m\n\u001b[0;32m   2672\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2673\u001b[0m                 \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2674\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_referents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2675\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_copy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2676\u001b[0m                     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import gc\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import lightgbm as lgb\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "import itertools\n",
    "import pickle, gzip\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime\n",
    "\n",
    "def multi_weighted_logloss_OLDVERSION(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    @author olivier https://www.kaggle.com/ogrellier\n",
    "    multi logloss for PLAsTiCC challenge\n",
    "    \"\"\"\n",
    "    # class_weights taken from Giba's topic : https://www.kaggle.com/titericz\n",
    "    # https://www.kaggle.com/c/PLAsTiCC-2018/discussion/67194\n",
    "    # with Kyle Boone's post https://www.kaggle.com/kyleboone\n",
    "    if len(np.unique(y_true)) == 14:\n",
    "        classes = [6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95]\n",
    "        class_weight = {6: 1, 15: 2, 16: 1, 42: 1, 52: 1, 53: 1, 62: 1, 64: 2, 65: 1, 67: 1, 88: 1, 90: 1, 92: 1, 95: 1}\n",
    "#     if len(np.unique(y_true)) > 14:\n",
    "#         classes.append(99)\n",
    "#         class_weight[99] = 2\n",
    "        \n",
    "    # Galaxy Case\n",
    "    if len(np.unique(y_true)) == 5:\n",
    "        classes = [6, 16, 53, 65, 92]\n",
    "        class_weight = {6: 1, 16: 1, 53: 1, 65: 1, 92: 1}\n",
    "        \n",
    "    # Out of Galaxy Case\n",
    "    if len(np.unique(y_true)) == 9:\n",
    "        classes = [15, 42, 52, 62, 64, 67, 88, 90, 95]\n",
    "        class_weight = {15: 2, 42: 1, 52: 1, 62: 1, 64: 2, 67: 1, 88: 1, 90: 1, 95: 1}    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    y_p = y_preds\n",
    "    # Trasform y_true in dummies\n",
    "    y_ohe = pd.get_dummies(y_true)\n",
    "    # Normalize rows and limit y_preds to 1e-15, 1-1e-15\n",
    "    y_p = np.clip(a=y_p, a_min=1e-15, a_max=1 - 1e-15)\n",
    "    # Transform to log\n",
    "    y_p_log = np.log(y_p)\n",
    "    # Get the log for ones, .values is used to drop the index of DataFrames\n",
    "    # Exclude class 99 for now, since there is no class99 in the training set\n",
    "    # we gave a special process for that class\n",
    "    y_log_ones = np.sum(y_ohe.values * y_p_log, axis=0)\n",
    "    # Get the number of positives for each class\n",
    "    nb_pos = y_ohe.sum(axis=0).values.astype(float)\n",
    "    # Weight average and divide by the number of positives\n",
    "    class_arr = np.array([class_weight[k] for k in sorted(class_weight.keys())])\n",
    "    y_w = y_log_ones * class_arr / nb_pos\n",
    "\n",
    "    loss = - np.sum(y_w) / np.sum(class_arr)\n",
    "    return loss\n",
    "    \n",
    "def set_df(arr, col_names):\n",
    "    df = pd.DataFrame(arr)\n",
    "    df.columns = col_names\n",
    "    return df\n",
    "\n",
    "def get_new_columns(aggs):\n",
    "    return [k + '_' + agg for k in aggs.keys() for agg in aggs[k]]\n",
    "\n",
    "def agg_by_flux_feats(df):\n",
    "    \n",
    "    df['flux_ratio'] = df['flux'] / df['flux_err']\n",
    "    \n",
    "    df['flux_ratio_sq'] = np.power(df['flux'] / df['flux_err'], 2.0)\n",
    "    df['flux_by_flux_ratio_sq'] = df['flux'] * df['flux_ratio_sq']\n",
    "    \n",
    "    aggs = {\n",
    "#         'mjd': ['min', 'max', 'size'],\n",
    "#         'passband': ['mean', 'std', 'var'],  \n",
    "        'flux': ['min', 'max', 'mean', 'median', 'std', 'skew'],\n",
    "        'flux_err': ['min', 'max', 'mean', 'median', 'std'],\n",
    "        'flux_ratio': ['min', 'max', 'mean', 'std'],\n",
    "        'detected': ['mean'],  # ''min', 'max', 'mean', 'median', 'std'],\n",
    "    }   \n",
    "\n",
    "#     aggs['flux_ratio_sq'] = ['sum']\n",
    "#     aggs['flux_by_flux_ratio_sq'] = ['sum']\n",
    "\n",
    "    \n",
    "    agg_df = df.groupby('object_id').agg(aggs)\n",
    "    new_columns = get_new_columns(aggs)\n",
    "    agg_df.columns = new_columns\n",
    "\n",
    "    agg_df = add_flux_second_order_features_to_agg(df=agg_df)\n",
    "    \n",
    "    return agg_df\n",
    "\n",
    "def add_flux_second_order_features_to_agg(df):\n",
    "#     df['mjd_diff'] = df['mjd_max'] - df['mjd_min']\n",
    "    df['flux_diff'] = df['flux_max'] - df['flux_min']\n",
    "    df['flux_dif2'] = (df['flux_max'] - df['flux_min']) / df['flux_mean']\n",
    "#     df['flux_w_mean'] = df['flux_by_flux_ratio_sq_sum'] / df['flux_ratio_sq_sum']\n",
    "#     df['flux_dif3'] = (df['flux_max'] - df['flux_min']) / df['flux_w_mean']\n",
    "\n",
    "#     del df['mjd_max'], df['mjd_min']\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_by_galaxy(df):\n",
    "    df_in_gal = df[df['in_galaxy']==1]\n",
    "    objects_in_gal = df_in_gal['object_id'].unique().tolist()\n",
    "    print('Number of objects in galaxy :',len(objects_in_gal))\n",
    "    \n",
    "    df_out_gal = df[df['in_galaxy']==0]\n",
    "    objects_out_gal = df_out_gal['object_id'].unique().tolist()\n",
    "    print('Number of objects out of galaxy :',len(objects_out_gal))\n",
    "    print('Just to check, sum of objects :', len(objects_in_gal) + len(objects_out_gal))\n",
    "    print('Total number should be', len(df['object_id'].unique().tolist()))\n",
    "    return df_in_gal, df_out_gal\n",
    "\n",
    "\n",
    "def add_feats_within_time_interval_out(int_n, df, db):\n",
    "    print('Number of Intervals :', int_n)\n",
    "    t_min = db.mjd.min()\n",
    "    t_max = db.mjd.max()\n",
    "    print('Min and Max MJD time : {}, {}'.format(t_min, t_max))    \n",
    "    int_dur = (t_max - t_min)/int_n\n",
    "    for i in range(int_n):\n",
    "        \n",
    "        db_fil = db[(db.mjd>=(t_min+i*int_dur))&(db.mjd<(t_min + (i+1)*int_dur))][['object_id','flux','passband']]\n",
    "        print('Interval #{}, record quantity: {}'.format(i+1, db_fil.shape[0]))\n",
    "        \n",
    "        # interval_#_flux_？\n",
    "        stats = db_fil.groupby('object_id', as_index=False)['flux'].agg({'interval_{}_flux_mean'.format(i+1):'mean',\n",
    "#                                                                           'interval_{}_flux_std'.format(i+1):'std',\n",
    "                                                                          'interval_{}_flux_min'.format(i+1):'min',\n",
    "                                                                          'interval_{}_flux_max'.format(i+1):'max',\n",
    "#                                                                          'interval_{}_flux_skew'.format(i+1):'skew'\n",
    "                                                                        })\n",
    "#         print('New features added: ',stats.columns.tolist())\n",
    "        df = df.merge(stats, on='object_id', how='left')\n",
    "        \n",
    "        \n",
    "#         # interval_#_band_#_flux_？\n",
    "#         stats = db_fil.groupby(['object_id','passband'])['flux'].skew().unstack()\n",
    "#         stats.columns = ['interval_{}_band_{}_flux_skew'.format(i+1, str(col)) for col in stats.columns.tolist()]\n",
    "#         print('Feats added:',stats.columns.tolist())\n",
    "#         stats['object_id'] = stats.index    \n",
    "#         df = df.merge(stats, on='object_id', how='left').fillna(0) \n",
    "        \n",
    "                \n",
    "#     # interval_#_flux_？ 互相做差\n",
    "#     for key in ['max', 'min', 'mean']:\n",
    "# #     for key in ['mean']:\n",
    "#         key_cols = ['interval_{}_flux_{}'.format(i, key) for i in range(1, int_n+1)]\n",
    "#         for col in key_cols:\n",
    "#             subtract_cols = [col_ for col_ in key_cols if col_ < col]\n",
    "#             for sub_col in subtract_cols:\n",
    "#                 df['{}_minus_{}'.format(col, sub_col)] = df[col] - df[sub_col]\n",
    "#                 print('Feature added:', '{}_minus_{}'.format(col, sub_col))\n",
    "        \n",
    "\n",
    "    \n",
    "    print('Dimension of data after adding features relevant to time intervals', df.shape)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_feats_within_time_interval(int_n, df, db):\n",
    "    print('Number of Intervals :', int_n)\n",
    "    t_min = db.mjd.min()\n",
    "    t_max = db.mjd.max()\n",
    "    print('Min and Max MJD time : {}, {}'.format(t_min, t_max))    \n",
    "    int_dur = (t_max - t_min)/int_n\n",
    "    for i in range(int_n):\n",
    "        \n",
    "        db_fil = db[(db.mjd>=(t_min+i*int_dur))&(db.mjd<(t_min + (i+1)*int_dur))][['object_id','flux','passband']]\n",
    "        print('Interval #{}, record quantity: {}'.format(i+1, db_fil.shape[0]))\n",
    "        \n",
    "        # interval_#_flux_？\n",
    "        stats = db_fil.groupby('object_id', as_index=False)['flux'].agg({'interval_{}_flux_mean'.format(i+1):'mean',\n",
    "                                                                          'interval_{}_flux_std'.format(i+1):'std',\n",
    "                                                                          'interval_{}_flux_min'.format(i+1):'min',\n",
    "                                                                          'interval_{}_flux_max'.format(i+1):'max',\n",
    "                                                                         'interval_{}_flux_skew'.format(i+1):'skew'})\n",
    "#         print('New features added: ',stats.columns.tolist())\n",
    "        df = df.merge(stats, on='object_id', how='left')\n",
    "        \n",
    "        \n",
    "#         # interval_#_band_#_flux_？\n",
    "#         stats = db_fil.groupby(['object_id','passband'])['flux'].skew().unstack()\n",
    "#         stats.columns = ['interval_{}_band_{}_flux_skew'.format(i+1, str(col)) for col in stats.columns.tolist()]\n",
    "#         print('Feats added:',stats.columns.tolist())\n",
    "#         stats['object_id'] = stats.index    \n",
    "#         df = df.merge(stats, on='object_id', how='left').fillna(0) \n",
    "        \n",
    "                \n",
    "    # interval_#_flux_？ 互相做差\n",
    "    for key in ['max', 'min', 'mean']:\n",
    "#     for key in ['max']:\n",
    "        key_cols = ['interval_{}_flux_{}'.format(i, key) for i in range(1, int_n+1)]\n",
    "        for col in key_cols:\n",
    "            subtract_cols = [col_ for col_ in key_cols if col_ < col]\n",
    "            for sub_col in subtract_cols:\n",
    "                df['{}_minus_{}'.format(col, sub_col)] = df[col] - df[sub_col]\n",
    "#                 print('Feature added:', '{}_minus_{}'.format(col, sub_col))\n",
    "        \n",
    "\n",
    "    \n",
    "    print('Dimension of data after adding features relevant to time intervals', df.shape)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_band_feats(df, db):\n",
    "    \n",
    "    \n",
    "### 均值\n",
    "    print('Adding feats for the flux mean per band...')\n",
    "    stats = db.groupby(['object_id','passband'])['flux'].mean().unstack()\n",
    "    stats.columns = ['band_' + str(col) + '_flux_mean' for col in stats.columns.tolist()]\n",
    "    \n",
    "    # band_#_flux_mean互相减去\n",
    "    mean_cols = stats.columns.tolist()\n",
    "    for col in mean_cols:\n",
    "        subtract_cols = [col_ for col_ in mean_cols if col_ < col]\n",
    "        for sub_col in subtract_cols:\n",
    "            stats['{}_minus_{}'.format(col, sub_col)] = stats[col] - stats[sub_col]\n",
    "      \n",
    "    # print('Feats added:',stats.columns.tolist())\n",
    "    stats['object_id'] = stats.index    \n",
    "    df = df.merge(stats, on='object_id', how='left').fillna(0)\n",
    "    \n",
    "    \n",
    "### 标准差    \n",
    "    print('Adding feats for the flux std per band...')\n",
    "    stats = db.groupby(['object_id','passband'])['flux'].std().unstack()\n",
    "    stats.columns = ['band_' + str(col) + '_flux_std' for col in stats.columns.tolist()]\n",
    "    # print('Feats added:',stats.columns.tolist())\n",
    "    stats['object_id'] = stats.index    \n",
    "    df = df.merge(stats, on='object_id', how='left').fillna(0)\n",
    "\n",
    "    \n",
    "### 偏度    \n",
    "    print('Adding feats for the flux skew per band...')\n",
    "    stats = db.groupby(['object_id','passband'])['flux'].skew().unstack()\n",
    "    stats.columns = ['band_' + str(col) + '_flux_skew' for col in stats.columns.tolist()]\n",
    "    # print('Feats added:',stats.columns.tolist())\n",
    "    stats['object_id'] = stats.index    \n",
    "    df = df.merge(stats, on='object_id', how='left').fillna(0) \n",
    "    \n",
    "\n",
    "### 最大值\n",
    "    print('Adding feats for the flux max per band...')\n",
    "    stats = db.groupby(['object_id','passband'])['flux'].max().unstack()\n",
    "    stats.columns = ['band_' + str(col) + '_flux_max' for col in stats.columns.tolist()]\n",
    "    # band_#_flux_max互相减去\n",
    "    max_cols = stats.columns.tolist()\n",
    "    for col in max_cols:\n",
    "        subtract_cols = [col_ for col_ in max_cols if col_ < col]\n",
    "        for sub_col in subtract_cols:\n",
    "            stats['{}_minus_{}'.format(col, sub_col)] = stats[col] - stats[sub_col]\n",
    "            \n",
    "    # print('Feats added:',stats.columns.tolist())\n",
    "    stats['object_id'] = stats.index    \n",
    "    df = df.merge(stats, on='object_id', how='left').fillna(0) \n",
    "    \n",
    "\n",
    "    \n",
    "### 最小值    \n",
    "    print('Adding feats for the flux min per band...')\n",
    "    stats = db.groupby(['object_id','passband'])['flux'].min().unstack()\n",
    "    stats.columns = ['band_' + str(col) + '_flux_min' for col in stats.columns.tolist()]\n",
    "    \n",
    "#     # band_#_flux_min互相做差\n",
    "#     min_cols = stats.columns.tolist()\n",
    "#     for col in min_cols:\n",
    "#         subtract_cols = [col_ for col_ in min_cols if col_ < col]\n",
    "#         for sub_col in subtract_cols:\n",
    "#             stats['{}_minus_{}'.format(col, sub_col)] = stats[col] - stats[sub_col]\n",
    "            \n",
    "    # print('Feats added:',stats.columns.tolist())\n",
    "    stats['object_id'] = stats.index    \n",
    "    df = df.merge(stats, on='object_id', how='left').fillna(0) \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "# ### ......  Mean\n",
    "#     print('Adding feats for the flux_err mean per band...')\n",
    "#     stats = db.groupby(['object_id','passband'])['flux_err'].mean().unstack()\n",
    "#     stats.columns = ['band_' + str(col) + '_flux_err_mean' for col in stats.columns.tolist()]      \n",
    "#     print('Feats added:',stats.columns.tolist())\n",
    "#     stats['object_id'] = stats.index    \n",
    "#     df = df.merge(stats, on='object_id', how='left').fillna(0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "### 遍历band_list计算 \n",
    "    print('Adding feats for the flux (max-min)/mean per band...')\n",
    "    for band_n in range(6):\n",
    "        df['band_' + str(band_n) + '_flux_diff1'] = df['band_' + str(band_n) + '_flux_max'] - df['band_' + str(band_n) + '_flux_min']\n",
    "        df['band_' + str(band_n) + '_flux_diff2'] = df['band_' + str(band_n) + '_flux_diff1']/df['band_' + str(band_n) + '_flux_mean']\n",
    "        # print('Feature added: band_' + str(band_n) + '_flux_diff2')\n",
    "        \n",
    "#         df['band_' + str(band_n) + '_flux_err_ratio'] = df['band_' + str(band_n) + '_flux_err_mean']/df['band_' + str(band_n) + '_flux_mean']\n",
    "#         print('Feature added: band_' + str(band_n) + '_flux_err_ratio')\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    print('Dimension of data after adding features relevant to bands', df.shape)\n",
    "    \n",
    "    return df\n",
    "\n",
    "    \n",
    "#     print('Adding feats for the flux mean per band...')\n",
    "#     stats = db.groupby(['object_id','passband'])['flux'].mean().unstack()\n",
    "#     stats['object_id'] = stats.index\n",
    "#     stats.columns = [str(col) + '_mean' for col in stats.columns.tolist()]\n",
    "#     df = df.merge(db, on='object_id', how='left').fillna(0)\n",
    "#     print('Feats added:',stats.columns.tolist())\n",
    "\n",
    "def add_flux_second_order_features_to_agg(df):\n",
    "#     df['mjd_diff'] = df['mjd_max'] - df['mjd_min']\n",
    "    df['flux_diff'] = df['flux_max'] - df['flux_min']\n",
    "    df['flux_dif2'] = (df['flux_max'] - df['flux_min']) / df['flux_mean']\n",
    "#     df['flux_w_mean'] = df['flux_by_flux_ratio_sq_sum'] / df['flux_ratio_sq_sum']\n",
    "#     df['flux_dif3'] = (df['flux_max'] - df['flux_min']) / df['flux_w_mean']\n",
    "\n",
    "#     del df['mjd_max'], df['mjd_min']\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_photo_feats(df):\n",
    "    df['hostgal_photoz_ratio'] = df['hostgal_photoz']/df['hostgal_photoz_err']\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def fabriquer_feat(db, meta):\n",
    "    \n",
    "    # # 去除无效特征\n",
    "    # del meta['hostgal_specz']\n",
    "    # print('Feature hostgal_specz is removed')\n",
    "    \n",
    "    # META数据提供划分银河系内外的依据\n",
    "    # 增加是否属于银河系的特征\n",
    "    meta.distmod.fillna(0,inplace=True)\n",
    "    meta['in_galaxy'] = 0\n",
    "    meta.loc[(meta.distmod == 0), 'in_galaxy'] = 1\n",
    "    \n",
    "    # 时序数据和META数据融合，形成以mjd为行的数据\n",
    "    db_meta = db.merge(meta, on='object_id', how='left')\n",
    "    print('Dimension of merge data for MJD relevant data and META data ', db_meta.shape)\n",
    "    \n",
    "    # 对时序融合数据进行分割\n",
    "    db_in_gal, db_out_gal = get_by_galaxy(db_meta)\n",
    "    print('Dimension of merge data for that in galaxy and that out of galaxy ', db_in_gal.shape, db_out_gal.shape)\n",
    "    \n",
    "    # 基本特征聚合\n",
    "    agg_df = agg_by_flux_feats(db)\n",
    "    print('Dimension of aggregated data on flux features', agg_df.shape)\n",
    "    \n",
    "    # 聚合数据和META数据融合，形成以object_id为行的数据\n",
    "    agg_df_meta = agg_df.merge(meta, on='object_id', how='left')\n",
    "    print('Dimension of merge data for Object relevant data and META data', agg_df_meta.shape)\n",
    "\n",
    "    # 对object融合数据进行分割\n",
    "    df_in_gal, df_out_gal = get_by_galaxy(agg_df_meta)\n",
    "    print('Dimension of merge data for that in galaxy and that out of galaxy ', df_in_gal.shape, df_out_gal.shape)\n",
    "\n",
    "    \n",
    "    # # 对银河系内外数据分别提取特征\n",
    "    # print('Features extraction begins...')\n",
    "    \n",
    "    # # 银河系内\n",
    "    # print('In terms of that in the Galaxy...')\n",
    "    \n",
    "    # # 增加band相关特征\n",
    "    # df_in_gal = add_band_feats(df_in_gal, db_in_gal)    \n",
    "    \n",
    "    # # 增加按MJD划分时间统计得到的特征\n",
    "    # df_in_gal = add_feats_within_time_interval(6, df_in_gal, db_in_gal)\n",
    "    \n",
    "    # # 银河系外\n",
    "    # print('In terms of that out of the Galaxy...')\n",
    "    \n",
    "    # # 增加hostgal_photoz相关特征\n",
    "    # df_out_gal = add_photo_feats(df_out_gal)\n",
    "    \n",
    "    # # 增加band相关特征\n",
    "    # df_out_gal = add_band_feats(df_out_gal, db_out_gal)    \n",
    "    \n",
    "    # # 增加按MJD划分时间统计得到的特征\n",
    "    # df_out_gal = add_feats_within_time_interval_out(6, df_out_gal, db_out_gal) \n",
    "    \n",
    "    return df_in_gal, df_out_gal\n",
    "    \n",
    "    \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,BatchNormalization,Dropout\n",
    "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def multi_weighted_logloss(y_ohe, y_p):\n",
    "    \"\"\"\n",
    "    @author olivier https://www.kaggle.com/ogrellier\n",
    "    multi logloss for PLAsTiCC challenge\n",
    "    \"\"\"\n",
    "#     classes = [6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95]\n",
    "#     class_weight = {6: 1, 15: 2, 16: 1, 42: 1, 52: 1, 53: 1, 62: 1, 64: 2, 65: 1, 67: 1, 88: 1, 90: 1, 92: 1, 95: 1}\n",
    "\n",
    "    print('Number of classes :', len(y_ohe[0]))\n",
    "    \n",
    "    if len(y_ohe[0]) == 14:\n",
    "        classes = [6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95]\n",
    "        class_weight = {6: 1, 15: 2, 16: 1, 42: 1, 52: 1, 53: 1, 62: 1, 64: 2, 65: 1, 67: 1, 88: 1, 90: 1, 92: 1, 95: 1}\n",
    "    \n",
    "    # Galaxy Case\n",
    "    if len(y_ohe[0]) == 5:\n",
    "        classes = [6, 16, 53, 65, 92]\n",
    "        class_weight = {6: 1, 16: 1, 53: 1, 65: 1, 92: 1}\n",
    "        \n",
    "    # Out of Galaxy Case\n",
    "    if len(y_ohe[0]) == 9:\n",
    "        classes = [15, 42, 52, 62, 64, 67, 88, 90, 95]\n",
    "        class_weight = {15: 2, 42: 1, 52: 1, 62: 1, 64: 2, 67: 1, 88: 1, 90: 1, 95: 1}\n",
    "        \n",
    "        \n",
    "    # Normalize rows and limit y_preds to 1e-15, 1-1e-15\n",
    "    y_p = np.clip(a=y_p, a_min=1e-15, a_max=1-1e-15)\n",
    "    # Transform to log\n",
    "    y_p_log = np.log(y_p)\n",
    "    # Get the log for ones, .values is used to drop the index of DataFrames\n",
    "    # Exclude class 99 for now, since there is no class99 in the training set \n",
    "    # we gave a special process for that class\n",
    "    y_log_ones = np.sum(y_ohe * y_p_log, axis=0)\n",
    "    # Get the number of positives for each class\n",
    "    nb_pos = y_ohe.sum(axis=0).astype(float)\n",
    "    # Weight average and divide by the number of positives\n",
    "    class_arr = np.array([class_weight[k] for k in sorted(class_weight.keys())])\n",
    "    y_w = y_log_ones * class_arr / nb_pos    \n",
    "    loss = - np.sum(y_w) / np.sum(class_arr)\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "def plot_loss_acc(history):\n",
    "    plt.plot(history.history['loss'][1:])\n",
    "    plt.plot(history.history['val_loss'][1:])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('val_loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train','Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history['acc'][1:])\n",
    "    plt.plot(history.history['val_acc'][1:])\n",
    "    plt.title('model Accuracy')\n",
    "    plt.ylabel('val_acc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train','Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def to_cat(y):    \n",
    "    classes = sorted(np.unique(y))\n",
    "    \n",
    "    unique_y = np.unique(y)\n",
    "    class_map = dict()\n",
    "\n",
    "    for i,val in enumerate(unique_y):\n",
    "        class_map[val] = i            \n",
    "    y_map = np.zeros((y.shape[0],))\n",
    "    y_map = np.array([class_map[val] for val in y])\n",
    "    y_categorical = to_categorical(y_map)    \n",
    "    \n",
    "    return y_categorical\n",
    "    \n",
    "    \n",
    "    \n",
    "def train_by_nn(full_train, y):\n",
    "    full_train_new = full_train.copy()\n",
    "    ss = StandardScaler()\n",
    "    full_train_ss = ss.fit_transform(full_train_new)\n",
    "    \n",
    "    classes = sorted(y.unique())\n",
    "    \n",
    "    unique_y = np.unique(y)\n",
    "    class_map = dict()\n",
    "\n",
    "    for i,val in enumerate(unique_y):\n",
    "        class_map[val] = i            \n",
    "    y_map = np.zeros((y.shape[0],))\n",
    "    y_map = np.array([class_map[val] for val in y])\n",
    "    y_categorical = to_categorical(y_map)    \n",
    "\n",
    "    \n",
    "    y_count = Counter(y_map)\n",
    "    wtable = np.zeros((len(unique_y),))\n",
    "    for i in range(len(unique_y)):\n",
    "        wtable[i] = y_count[i]/y_map.shape[0]    \n",
    "    \n",
    "    \n",
    "    def mywloss(y_true, y_pred):  \n",
    "  \n",
    "        yc=tf.clip_by_value(y_pred,1e-15,1-1e-15)\n",
    "        loss=-(tf.reduce_mean(tf.reduce_mean(y_true*tf.log(yc),axis=0)/wtable))\n",
    "        return loss\n",
    "    \n",
    "#     K.clear_session()\n",
    "    def build_model(dropout_rate=0.25,activation='relu'):\n",
    "        start_neurons = 512\n",
    "        # create model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(start_neurons, input_dim=full_train_ss.shape[1], activation=activation))\n",
    "        # model.add(BatchNormalization())\n",
    "        # model.add(Dropout(dropout_rate))\n",
    "        \n",
    "        # model.add(Dense(start_neurons//2,activation=activation))\n",
    "        # model.add(BatchNormalization())\n",
    "        # model.add(Dropout(dropout_rate))\n",
    "        \n",
    "        # model.add(Dense(start_neurons//4,activation=activation))\n",
    "        # model.add(BatchNormalization())\n",
    "        # model.add(Dropout(dropout_rate))\n",
    "        \n",
    "        # model.add(Dense(start_neurons//8,activation=activation))\n",
    "        # model.add(BatchNormalization())\n",
    "        # model.add(Dropout(dropout_rate/2))\n",
    "        \n",
    "        model.add(Dense(len(classes), activation='softmax'))\n",
    "        return model    \n",
    "    \n",
    "        \n",
    "    clfs = []\n",
    "    oof_preds = np.zeros((len(full_train_ss), len(classes)))\n",
    "    epochs = 600\n",
    "    batch_size = 100\n",
    "    checkPoint = ModelCheckpoint(\"./keras.model\",monitor='val_loss',mode = 'min', save_best_only=True, verbose=0)\n",
    "    for fold_, (trn_, val_) in enumerate(folds.split(y_map, y_map)):\n",
    "        x_train, y_train = full_train_ss[trn_], y_categorical[trn_]\n",
    "        x_valid, y_valid = full_train_ss[val_], y_categorical[val_]\n",
    "        \n",
    "        model = build_model(dropout_rate=0.5,activation='tanh')    \n",
    "        model.compile(loss=mywloss, optimizer='adam', metrics=['accuracy'])\n",
    "        history = model.fit(x_train, y_train,\n",
    "                        validation_data=[x_valid, y_valid], \n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,shuffle=True,verbose=0,callbacks=[checkPoint])       \n",
    "        \n",
    "        plot_loss_acc(history)\n",
    "        \n",
    "        print('Loading Best Model')\n",
    "        model.load_weights('./keras.model')\n",
    "        # # Get predicted probabilities for each class\n",
    "        oof_preds[val_, :] = model.predict_proba(x_valid,batch_size=batch_size)\n",
    "        print(multi_weighted_logloss(y_valid, model.predict_proba(x_valid,batch_size=batch_size)))\n",
    "        clfs.append(model)\n",
    "    \n",
    "    return ss, y_categorical, oof_preds, clfs\n",
    "\n",
    "\n",
    "gc.enable()\n",
    "\n",
    "train = pd.read_csv('../input/training_set.csv')\n",
    "\n",
    "meta_train = pd.read_csv('../input/training_set_metadata.csv')\n",
    "\n",
    "# 去除无效特征\n",
    "del meta_train['hostgal_specz']\n",
    "print('Feature hostgal_specz is removed')\n",
    "\n",
    "full_train_in_gal, full_train_out_gal = fabriquer_feat(train, meta_train)\n",
    "\n",
    "for df in [full_train_in_gal, full_train_out_gal]:\n",
    "    del df['object_id']\n",
    "    df_mean = df.mean(axis=0)\n",
    "    df.fillna(df_mean, inplace=True)\n",
    "\n",
    "del train\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "y_in_gal = full_train_in_gal['target']\n",
    "\n",
    "train_in_gal = full_train_in_gal.copy()\n",
    "\n",
    "del train_in_gal['target']\n",
    "\n",
    "# print('Training begins...')\n",
    "\n",
    "val_score_list = []\n",
    "clf_list = []\n",
    "\n",
    "ss_in, y_categorical_in_gal, oof_preds_in_gal, clf_in = train_by_nn(train_in_gal, y_in_gal)\n",
    "\n",
    "score_in_gal = multi_weighted_logloss(y_categorical_in_gal,oof_preds_in_gal)\n",
    "print('MULTI WEIGHTED LOG LOSS : %.5f ' % score_in_gal)\n",
    "val_score_list.append(score_in_gal)\n",
    "clf_list.append(clf_in)\n",
    "\n",
    "\n",
    "y_out_gal = full_train_out_gal['target']\n",
    "\n",
    "train_out_gal = full_train_out_gal.copy()\n",
    "\n",
    "del train_out_gal['target']\n",
    "\n",
    "ss_out, y_categorical_out_gal, oof_preds_out_gal, clf_out = train_by_nn(train_out_gal, y_out_gal)\n",
    "\n",
    "score_out_gal = multi_weighted_logloss(y_categorical_out_gal,oof_preds_out_gal)\n",
    "print('MULTI WEIGHTED LOG LOSS : %.5f ' % score_out_gal)\n",
    "val_score_list.append(score_out_gal)\n",
    "clf_list.append(clf_out)\n",
    "\n",
    "\n",
    "all_y = np.concatenate((y_in_gal.values, y_out_gal.values), axis=0)\n",
    "\n",
    "in_classes = [6, 16, 53, 65, 92]\n",
    "out_classes = [15, 42, 52, 62, 64, 67, 88, 90, 95]\n",
    "\n",
    "in_df = set_df(oof_preds_in_gal, in_classes)\n",
    "out_df = set_df(oof_preds_out_gal, out_classes)\n",
    "in_out_df = pd.concat([in_df, out_df], axis=0).fillna(0)\n",
    "\n",
    "\n",
    "print('Just double check:', multi_weighted_logloss_OLDVERSION(y_true=all_y, y_preds=in_out_df.values))\n",
    "\n",
    "all_y_cat = to_cat(all_y)\n",
    "\n",
    "tot_score = multi_weighted_logloss(all_y_cat, in_out_df.values)\n",
    "print('MULTI WEIGHTED LOG LOSS : %.5f ' % tot_score)\n",
    "\n",
    "val_score_list.append(tot_score)\n",
    "\n",
    "\n",
    "\n",
    "score_tab = pd.DataFrame({'Model':['Galaxy_Model', 'Extragalaxy_Model','Bi_Model'], 'Score':val_score_list})\n",
    "print(score_tab)\n",
    "\n",
    "\n",
    "# 结果存档\n",
    "# score_tab.to_csv(r'../feat/validation_scores_{}.csv'.format(datetime.datetime.now().strftime('%m%d_%H%M')), index=False)\n",
    "\n",
    "\n",
    "# def plot_confusion_matrix(cm, classes,\n",
    "#                           normalize=False,\n",
    "#                           title='Confusion matrix',\n",
    "#                           cmap=plt.cm.Blues):\n",
    "#     \"\"\"\n",
    "#     This function prints and plots the confusion matrix.\n",
    "#     Normalization can be applied by setting `normalize=True`.\n",
    "#     \"\"\"\n",
    "#     if normalize:\n",
    "#         cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#         print(\"Normalized confusion matrix\")\n",
    "#     else:\n",
    "#         print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "#     fig = plt.figure(figsize=(20,10))\n",
    "    \n",
    "#     plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     plt.title(title)\n",
    "#     plt.colorbar()\n",
    "#     tick_marks = np.arange(len(classes))\n",
    "#     plt.xticks(tick_marks, classes, rotation=45)\n",
    "#     plt.yticks(tick_marks, classes)\n",
    "\n",
    "#     fmt = '.2f' if normalize else 'd'\n",
    "#     thresh = cm.max() / 2.\n",
    "#     for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "#         plt.text(j, i, format(cm[i, j], fmt),\n",
    "#                  horizontalalignment=\"center\",\n",
    "#                  color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "#     plt.ylabel('True label')\n",
    "#     plt.xlabel('Predicted label')\n",
    "#     plt.tight_layout()\n",
    "    \n",
    "#     fig.savefig(r'../feat/confusion_matrix_{}.pdf'.format(datetime.datetime.now().strftime('%m%d_%H%M')))\n",
    "    \n",
    "    \n",
    "\n",
    "# def get_confusion_matrix(y, preds):\n",
    "#     unique_y = np.unique(y)\n",
    "#     class_map = dict()\n",
    "#     for i,val in enumerate(unique_y):\n",
    "#         class_map[val] = i\n",
    "            \n",
    "# #     y_map = np.zeros((y.shape[0],))\n",
    "#     y_map = np.array([class_map[val] for val in y]) \n",
    "    \n",
    "#     cnf_matrix = confusion_matrix(y_map, np.argmax(preds, axis=-1))  \n",
    "#     np.set_printoptions(precision=2)\n",
    "    \n",
    "    \n",
    "#     sample_sub = pd.read_csv('../input/sample_submission.csv')\n",
    "#     class_names = list(sample_sub.columns[1:-1])\n",
    "#     del sample_sub;gc.collect()\n",
    "    \n",
    "#     # Plot non-normalized confusion matrix\n",
    "#     plt.figure(figsize=(10,10))\n",
    "#     foo = plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "#                           title='Confusion matrix')\n",
    "    \n",
    "\n",
    "# get_confusion_matrix(all_y, in_out_df.values)   \n",
    "\n",
    "\n",
    "# def predict_chunk(df_, clfs_, meta_, features, train_mean):\n",
    "    \n",
    "#     print('Chunk size',df_.shape[0])\n",
    "    \n",
    "\n",
    "#     full_test_in_gal, full_test_out_gal = fabriquer_feat(df_, meta_)\n",
    "        \n",
    "\n",
    "\n",
    "#     in_classes = [6, 16, 53, 65, 92]\n",
    "#     out_classes = [15, 42, 52, 62, 64, 67, 88, 90, 95] \n",
    "\n",
    "#     if full_test_in_gal.shape[0] == 0:\n",
    "#         in_df = pd.DataFrame(columns=in_classes)\n",
    "#         in_ids = []\n",
    "        \n",
    "    \n",
    "#     else :\n",
    "#         in_ids = full_test_in_gal['object_id'].astype(np.int64).values\n",
    "        \n",
    "#         del full_test_in_gal['object_id']\n",
    "#         df_mean = full_test_in_gal.mean(axis=0)\n",
    "#         full_test_in_gal.fillna(df_mean, inplace=True)\n",
    "    \n",
    "#         # Make predictions in galaxy\n",
    "#         preds_in_gal = None\n",
    "#         for clf in clfs_[0]:\n",
    "#             if preds_in_gal is None:\n",
    "#                 preds_in_gal = clf.predict_proba(full_test_in_gal[features[0]]) / len(clfs_[0])\n",
    "#             else:\n",
    "#                 preds_in_gal += clf.predict_proba(full_test_in_gal[features[0]]) / len(clfs_[0])\n",
    "        \n",
    "#         in_df = set_df(preds_in_gal, in_classes)\n",
    "        \n",
    "            \n",
    "\n",
    "#     if full_test_out_gal.shape[0] == 0:\n",
    "#         out_df = pd.DataFrame(columns=out_classes)    \n",
    "#         out_ids = []\n",
    "    \n",
    "#     else :\n",
    "#         out_ids = full_test_out_gal['object_id'].astype(np.int64).values\n",
    "        \n",
    "#         del full_test_out_gal['object_id']\n",
    "#         df_mean = full_test_out_gal.mean(axis=0)\n",
    "#         full_test_out_gal.fillna(df_mean, inplace=True)\n",
    "                \n",
    "#         # Make predictions out of galaxy\n",
    "#         preds_out_gal = None\n",
    "#         for clf in clfs_[1]:\n",
    "#             if preds_out_gal is None:\n",
    "#                 preds_out_gal = clf.predict_proba(full_test_out_gal[features[1]]) / len(clfs_[1])\n",
    "#             else:\n",
    "#                 preds_out_gal += clf.predict_proba(full_test_out_gal[features[1]]) / len(clfs_[1])\n",
    "        \n",
    "#         out_df = set_df(preds_out_gal, out_classes)\n",
    "        \n",
    "#     # Merge predictions\n",
    "#     in_out_df = pd.concat([in_df, out_df], axis=0).fillna(0)\n",
    "#     print(in_out_df.shape)\n",
    "    \n",
    "#     preds_ = in_out_df.values\n",
    "    \n",
    "            \n",
    "#     # Compute preds_99 as the proba of class not being any of the others\n",
    "#     # preds_99 = 0.1 gives 1.769\n",
    "#     preds_99 = np.ones(preds_.shape[0])\n",
    "#     for i in range(preds_.shape[1]):\n",
    "#         preds_99 *= (1 - preds_[:, i])\n",
    "\n",
    "#     # Create DataFrame from predictions\n",
    "#     classes = [6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95]\n",
    "    \n",
    "# #     preds_df_ = pd.DataFrame(preds_, columns=['class_' + str(s) for s in clfs_[0].classes_])\n",
    "#     preds_df_ = pd.DataFrame(preds_, columns=['class_' + str(s) for s in classes])\n",
    "#     preds_df_['object_id'] = np.concatenate((in_ids,out_ids), axis=0)\n",
    "#     preds_df_['class_99'] = 0.14 * preds_99 / np.mean(preds_99) \n",
    "\n",
    "#     print(preds_df_['class_99'].mean())\n",
    "\n",
    "#     del full_test_in_gal, full_test_out_gal, preds_, in_out_df\n",
    "#     gc.collect()\n",
    "\n",
    "#     return preds_df_\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature hostgal_specz is removed\n",
      "Chunk size 299671\n",
      "Dimension of merge data for MJD relevant data and META data  (299671, 16)\n",
      "Number of objects in galaxy : 8\n",
      "Number of objects out of galaxy : 903\n",
      "Just to check, sum of objects : 911\n",
      "Total number should be 911\n",
      "Dimension of merge data for that in galaxy and that out of galaxy  (2693, 16) (296978, 16)\n",
      "Dimension of aggregated data on flux features (911, 18)\n",
      "Dimension of merge data for Object relevant data and META data (911, 29)\n",
      "Number of objects in galaxy : 8\n",
      "Number of objects out of galaxy : 903\n",
      "Just to check, sum of objects : 911\n",
      "Total number should be 911\n",
      "Dimension of merge data for that in galaxy and that out of galaxy  (8, 29) (903, 29)\n",
      "[[1.2057380e-12 9.9999994e-01 1.6119472e-10 1.1710746e-08 4.0069356e-08]\n",
      " [5.5115675e-06 7.0158837e-11 7.0971856e-03 1.1813074e-14 9.9289739e-01]\n",
      " [7.7331928e-04 2.1569174e-05 3.6166642e-10 9.9920511e-01 3.3698091e-09]\n",
      " [2.5158724e-09 1.5589438e-03 7.0159696e-04 1.6265709e-17 9.9773937e-01]\n",
      " [9.9995518e-01 2.0329697e-15 4.4585926e-05 8.6381853e-11 2.3700653e-07]\n",
      " [1.7100871e-02 1.4770856e-02 5.3054458e-07 9.6665102e-01 1.4766677e-03]\n",
      " [2.9846628e-08 4.4333035e-08 3.5870925e-04 5.5687490e-14 9.9964118e-01]\n",
      " [3.4140944e-02 1.1376299e-06 2.1270952e-04 5.4522498e-05 9.6559078e-01]]\n",
      "(911, 14)\n",
      "0.14\n",
      "Chunk size 300063\n",
      "Dimension of merge data for MJD relevant data and META data  (300063, 16)\n",
      "Number of objects in galaxy : 5\n",
      "Number of objects out of galaxy : 905\n",
      "Just to check, sum of objects : 910\n",
      "Total number should be 910\n",
      "Dimension of merge data for that in galaxy and that out of galaxy  (1659, 16) (298404, 16)\n",
      "Dimension of aggregated data on flux features (910, 18)\n",
      "Dimension of merge data for Object relevant data and META data (910, 29)\n",
      "Number of objects in galaxy : 5\n",
      "Number of objects out of galaxy : 905\n",
      "Just to check, sum of objects : 910\n",
      "Total number should be 910\n",
      "Dimension of merge data for that in galaxy and that out of galaxy  (5, 29) (905, 29)\n",
      "[[4.7152895e-05 3.5629603e-11 2.9521335e-10 9.9995279e-01 3.1214323e-11]\n",
      " [4.8123780e-05 4.6182968e-13 3.5979268e-03 7.0447315e-11 9.9635386e-01]\n",
      " [5.2706234e-08 2.0740217e-08 5.2200316e-04 9.5620313e-15 9.9947798e-01]\n",
      " [1.5830285e-08 7.6647400e-04 6.6810363e-04 1.6223009e-13 9.9856544e-01]\n",
      " [4.0134332e-01 1.6049638e-01 9.9610159e-05 4.2024982e-01 1.7810863e-02]]\n",
      "(910, 14)\n",
      "0.13999999999999999\n",
      "Chunk size 300246\n",
      "Dimension of merge data for MJD relevant data and META data  (300246, 16)\n",
      "Number of objects in galaxy : 3\n",
      "Number of objects out of galaxy : 908\n",
      "Just to check, sum of objects : 911\n",
      "Total number should be 911\n",
      "Dimension of merge data for that in galaxy and that out of galaxy  (1032, 16) (299214, 16)\n",
      "Dimension of aggregated data on flux features (911, 18)\n",
      "Dimension of merge data for Object relevant data and META data (911, 29)\n",
      "Number of objects in galaxy : 3\n",
      "Number of objects out of galaxy : 908\n",
      "Just to check, sum of objects : 911\n",
      "Total number should be 911\n",
      "Dimension of merge data for that in galaxy and that out of galaxy  (3, 29) (908, 29)\n",
      "[[1.0318368e-07 3.2867026e-06 1.0954171e-04 8.4004254e-17 9.9988711e-01]\n",
      " [5.4563418e-07 6.4957068e-11 1.2179783e-03 9.0634349e-12 9.9878150e-01]\n",
      " [8.8840546e-03 1.6191534e-05 1.0952197e-08 9.9109972e-01 3.1268158e-08]]\n",
      "(911, 14)\n",
      "0.14\n",
      "Chunk size 99760\n",
      "Dimension of merge data for MJD relevant data and META data  (99760, 16)\n",
      "Number of objects in galaxy : 1\n",
      "Number of objects out of galaxy : 302\n",
      "Just to check, sum of objects : 303\n",
      "Total number should be 303\n",
      "Dimension of merge data for that in galaxy and that out of galaxy  (330, 16) (99430, 16)\n",
      "Dimension of aggregated data on flux features (303, 18)\n",
      "Dimension of merge data for Object relevant data and META data (303, 29)\n",
      "Number of objects in galaxy : 1\n",
      "Number of objects out of galaxy : 302\n",
      "Just to check, sum of objects : 303\n",
      "Total number should be 303\n",
      "Dimension of merge data for that in galaxy and that out of galaxy  (1, 29) (302, 29)\n",
      "[[2.5529337e-08 6.8882421e-02 2.7354943e-04 8.1495316e-17 9.3084407e-01]]\n",
      "(303, 14)\n",
      "0.14000000000000004\n",
      "Chunk size 260\n",
      "Dimension of merge data for MJD relevant data and META data  (260, 16)\n",
      "Number of objects in galaxy : 0\n",
      "Number of objects out of galaxy : 1\n",
      "Just to check, sum of objects : 1\n",
      "Total number should be 1\n",
      "Dimension of merge data for that in galaxy and that out of galaxy  (0, 16) (260, 16)\n",
      "Dimension of aggregated data on flux features (1, 18)\n",
      "Dimension of merge data for Object relevant data and META data (1, 29)\n",
      "Number of objects in galaxy : 0\n",
      "Number of objects out of galaxy : 1\n",
      "Just to check, sum of objects : 1\n",
      "Total number should be 1\n",
      "Dimension of merge data for that in galaxy and that out of galaxy  (0, 29) (1, 29)\n",
      "(1, 14)\n",
      "0.14\n"
     ]
    }
   ],
   "source": [
    "def predict_chunk(df_, clf_in, clf_out, meta_, features, ss_in, ss_out, train_mean):\n",
    "    \n",
    "    print('Chunk size',df_.shape[0])\n",
    "    \n",
    "\n",
    "    full_test_in_gal, full_test_out_gal = fabriquer_feat(df_, meta_)\n",
    "        \n",
    "\n",
    "\n",
    "    in_classes = [6, 16, 53, 65, 92]\n",
    "    out_classes = [15, 42, 52, 62, 64, 67, 88, 90, 95] \n",
    "\n",
    "    if full_test_in_gal.shape[0] == 0:\n",
    "        in_df = pd.DataFrame(columns=in_classes)\n",
    "        in_ids = []\n",
    "        \n",
    "    \n",
    "    else :\n",
    "        in_ids = full_test_in_gal['object_id'].astype(np.int64).values\n",
    "        \n",
    "        del full_test_in_gal['object_id']\n",
    "        df_mean = full_test_in_gal.mean(axis=0)\n",
    "        full_test_in_gal.fillna(df_mean, inplace=True)\n",
    "        ss_in_gal = ss_in.transform(full_test_in_gal[features[0]])\n",
    "    \n",
    "        # Make predictions in galaxy\n",
    "        preds_in_gal = None\n",
    "        for clf in clf_in:\n",
    "            if preds_in_gal is None:\n",
    "                preds_in_gal = clf.predict_proba(ss_in_gal) / len(clf_in)\n",
    "            else:\n",
    "                preds_in_gal += clf.predict_proba(ss_in_gal) / len(clf_in)\n",
    "        \n",
    "        in_df = set_df(preds_in_gal, in_classes)\n",
    "        \n",
    "            \n",
    "\n",
    "    if full_test_out_gal.shape[0] == 0:\n",
    "        out_df = pd.DataFrame(columns=out_classes)    \n",
    "        out_ids = []\n",
    "    \n",
    "    else :\n",
    "        out_ids = full_test_out_gal['object_id'].astype(np.int64).values\n",
    "        \n",
    "        del full_test_out_gal['object_id']\n",
    "        df_mean = full_test_out_gal.mean(axis=0)\n",
    "        full_test_out_gal.fillna(df_mean, inplace=True)\n",
    "        ss_out_gal = ss_out.transform(full_test_out_gal[features[1]])\n",
    "                \n",
    "        # Make predictions out of galaxy\n",
    "        preds_out_gal = None\n",
    "        for clf in clf_out:\n",
    "            if preds_out_gal is None:\n",
    "                preds_out_gal = clf.predict_proba(ss_out_gal) / len(clf_out)\n",
    "            else:\n",
    "                preds_out_gal += clf.predict_proba(ss_out_gal) / len(clf_out)\n",
    "        \n",
    "        out_df = set_df(preds_out_gal, out_classes)\n",
    "        \n",
    "    # Merge predictions\n",
    "    in_out_df = pd.concat([in_df, out_df], axis=0).fillna(0)\n",
    "    print(in_out_df.shape)\n",
    "    \n",
    "    preds_ = in_out_df.values\n",
    "    \n",
    "            \n",
    "    # Compute preds_99 as the proba of class not being any of the others\n",
    "    # preds_99 = 0.1 gives 1.769\n",
    "    preds_99 = np.ones(preds_.shape[0])\n",
    "    for i in range(preds_.shape[1]):\n",
    "        preds_99 *= (1 - preds_[:, i])\n",
    "\n",
    "    # Create DataFrame from predictions\n",
    "    classes = [6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95]\n",
    "    \n",
    "#     preds_df_ = pd.DataFrame(preds_, columns=['class_' + str(s) for s in clfs_[0].classes_])\n",
    "    preds_df_ = pd.DataFrame(preds_, columns=['class_' + str(s) for s in classes])\n",
    "    preds_df_['object_id'] = np.concatenate((in_ids,out_ids), axis=0)\n",
    "    preds_df_['class_99'] = 0.14 * preds_99 / np.mean(preds_99) \n",
    "\n",
    "    print(preds_df_['class_99'].mean())\n",
    "\n",
    "    del full_test_in_gal, full_test_out_gal, preds_, in_out_df\n",
    "    gc.collect()\n",
    "\n",
    "    return preds_df_\n",
    "\n",
    "\n",
    "meta_test = pd.read_csv('../input/test_set_metadata.csv')\n",
    "# 去除无效特征\n",
    "del meta_test['hostgal_specz']\n",
    "print('Feature hostgal_specz is removed')\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "# chunks = 5000000\n",
    "chunks = 300000\n",
    "remain_df = None\n",
    "\n",
    "for i_c, df in enumerate(pd.read_csv('../input/test_set_sample.csv', chunksize=chunks, iterator=True)):\n",
    "    # Check object_ids\n",
    "    # I believe np.unique keeps the order of group_ids as they appear in the file\n",
    "    unique_ids = np.unique(df['object_id'])\n",
    "    # 最后一个ID的内容\n",
    "    new_remain_df = df.loc[df['object_id'] == unique_ids[-1]].copy()\n",
    "\n",
    "    if remain_df is None:\n",
    "        #  除最后一个ID外的内容\n",
    "        df = df.loc[df['object_id'].isin(unique_ids[:-1])].copy()\n",
    "    else:\n",
    "        df = pd.concat([remain_df, df.loc[df['object_id'].isin(unique_ids[:-1])]], axis=0)\n",
    "\n",
    "    # Create remaining samples df\n",
    "    remain_df = new_remain_df\n",
    "    \n",
    "    \n",
    "\n",
    "    preds_df = predict_chunk(df_=df,\n",
    "                             clf_in=clf_in, clf_out=clf_out,\n",
    "                             meta_=meta_test,\n",
    "                             features=[train_in_gal.columns, train_out_gal.columns],\n",
    "                             ss_in=ss_in, ss_out=ss_out, train_mean=None) \n",
    "\n",
    "    if i_c == 0:\n",
    "        preds_df.to_csv('predictions_v3.csv', header=True, index=False, float_format='%.6f')\n",
    "    else:\n",
    "        preds_df.to_csv('predictions_v3.csv', header=False, mode='a', index=False, float_format='%.6f')\n",
    "\n",
    "    del preds_df\n",
    "    gc.collect()\n",
    "\n",
    "    if (i_c + 1) % 5 == 0:\n",
    "        # get_logger().info('%15d done in %5.1f' % (chunks * (i_c + 1), (time.time() - start) / 60))\n",
    "        # print('%15d done in %5.1f' % (chunks * (i_c + 1), (time.time() - start) / 60))\n",
    "        print('%15d done in %5.1f' % (chunks * (i_c + 1), (time.time() - start) / 60))\n",
    "        print('Progress percentage : %5.2f' % (chunks * (i_c + 1)/500000000))\n",
    "        print('Time estimated left : %5.2f' % ((time.time() - start) / 60 * (500000000-chunks * (i_c + 1))/(chunks * (i_c + 1))))\n",
    "\n",
    "# Compute last object in remain_df\n",
    "\n",
    "preds_df = predict_chunk(df_=remain_df,\n",
    "                         clf_in=clf_in, clf_out=clf_out,\n",
    "                         meta_=meta_test,\n",
    "                         features=[train_in_gal.columns, train_out_gal.columns],\n",
    "                         ss_in=ss_in, ss_out=ss_out, train_mean=None)\n",
    "\n",
    "preds_df.to_csv('predictions_v3.csv', header=False, mode='a', index=False, float_format='%.6f')\n",
    "\n",
    "z = pd.read_csv('predictions_v3.csv')\n",
    "\n",
    "z = z.groupby('object_id').mean()\n",
    "\n",
    "z.to_csv('single_predictions_v3.csv', index=True, float_format='%.6f')\n",
    "\n",
    "z = z.astype(np.float32)\n",
    "\n",
    "z['object_id'] = z.index.astype(np.int32)\n",
    "\n",
    "z = z.drop_duplicates(subset=['object_id'], keep='first')\n",
    "\n",
    "z.to_csv('single_predictions_v3.gz', index=False, float_format='%.6f', compression='gzip')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM 和 NN 的融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ans_nn = pd.read_csv('../result/nn_1101_lb_1290.csv')\n",
    "ans_lgb = pd.read_csv('../result/lgb_1030_lb_1387.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3492890 entries, 0 to 3492889\n",
      "Data columns (total 16 columns):\n",
      "class_6      float64\n",
      "class_15     float64\n",
      "class_16     float64\n",
      "class_42     float64\n",
      "class_52     float64\n",
      "class_53     float64\n",
      "class_62     float64\n",
      "class_64     float64\n",
      "class_65     float64\n",
      "class_67     float64\n",
      "class_88     float64\n",
      "class_90     float64\n",
      "class_92     float64\n",
      "class_95     float64\n",
      "class_99     float64\n",
      "object_id    int64\n",
      "dtypes: float64(15), int64(1)\n",
      "memory usage: 426.4 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3492890 entries, 0 to 3492889\n",
      "Data columns (total 16 columns):\n",
      "class_6      float64\n",
      "class_15     float64\n",
      "class_16     float64\n",
      "class_42     float64\n",
      "class_52     float64\n",
      "class_53     float64\n",
      "class_62     float64\n",
      "class_64     float64\n",
      "class_65     float64\n",
      "class_67     float64\n",
      "class_88     float64\n",
      "class_90     float64\n",
      "class_92     float64\n",
      "class_95     float64\n",
      "class_99     float64\n",
      "object_id    int64\n",
      "dtypes: float64(15), int64(1)\n",
      "memory usage: 426.4 MB\n"
     ]
    }
   ],
   "source": [
    "ans_nn.info()\n",
    "ans_lgb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_6</th>\n",
       "      <th>class_15</th>\n",
       "      <th>class_16</th>\n",
       "      <th>class_42</th>\n",
       "      <th>class_52</th>\n",
       "      <th>class_53</th>\n",
       "      <th>class_62</th>\n",
       "      <th>class_64</th>\n",
       "      <th>class_65</th>\n",
       "      <th>class_67</th>\n",
       "      <th>class_88</th>\n",
       "      <th>class_90</th>\n",
       "      <th>class_92</th>\n",
       "      <th>class_95</th>\n",
       "      <th>class_99</th>\n",
       "      <th>object_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2800897</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176699</td>\n",
       "      <td>0.139613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167149</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181025</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.324785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.194904</td>\n",
       "      <td>104853812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         class_6  class_15  class_16  class_42  class_52  class_53  class_62  \\\n",
       "2800897      0.0  0.010489       0.0  0.176699  0.139613       0.0  0.167149   \n",
       "\n",
       "         class_64  class_65  class_67  class_88  class_90  class_92  class_95  \\\n",
       "2800897  0.000083       0.0  0.181025  0.000018  0.324785       0.0  0.000138   \n",
       "\n",
       "         class_99  object_id  \n",
       "2800897  0.194904  104853812  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 首先把那个该死的最后一个object用lgb结果替换\n",
    "ans_nn[ans_nn.object_id == 104853812]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_6</th>\n",
       "      <th>class_15</th>\n",
       "      <th>class_16</th>\n",
       "      <th>class_42</th>\n",
       "      <th>class_52</th>\n",
       "      <th>class_53</th>\n",
       "      <th>class_62</th>\n",
       "      <th>class_64</th>\n",
       "      <th>class_65</th>\n",
       "      <th>class_67</th>\n",
       "      <th>class_88</th>\n",
       "      <th>class_90</th>\n",
       "      <th>class_92</th>\n",
       "      <th>class_95</th>\n",
       "      <th>class_99</th>\n",
       "      <th>object_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2800897</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.161452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206929</td>\n",
       "      <td>0.011763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043358</td>\n",
       "      <td>0.029377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011671</td>\n",
       "      <td>0.028226</td>\n",
       "      <td>0.464431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042792</td>\n",
       "      <td>0.14</td>\n",
       "      <td>104853812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         class_6  class_15  class_16  class_42  class_52  class_53  class_62  \\\n",
       "2800897      0.0  0.161452       0.0  0.206929  0.011763       0.0  0.043358   \n",
       "\n",
       "         class_64  class_65  class_67  class_88  class_90  class_92  class_95  \\\n",
       "2800897  0.029377       0.0  0.011671  0.028226  0.464431       0.0  0.042792   \n",
       "\n",
       "         class_99  object_id  \n",
       "2800897      0.14  104853812  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_lgb[ans_lgb.object_id == 104853812]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_nn[ans_nn.object_id == 104853812] = ans_lgb[ans_lgb.object_id == 104853812]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_6</th>\n",
       "      <th>class_15</th>\n",
       "      <th>class_16</th>\n",
       "      <th>class_42</th>\n",
       "      <th>class_52</th>\n",
       "      <th>class_53</th>\n",
       "      <th>class_62</th>\n",
       "      <th>class_64</th>\n",
       "      <th>class_65</th>\n",
       "      <th>class_67</th>\n",
       "      <th>class_88</th>\n",
       "      <th>class_90</th>\n",
       "      <th>class_92</th>\n",
       "      <th>class_95</th>\n",
       "      <th>class_99</th>\n",
       "      <th>object_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2800897</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.161452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206929</td>\n",
       "      <td>0.011763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043358</td>\n",
       "      <td>0.029377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011671</td>\n",
       "      <td>0.028226</td>\n",
       "      <td>0.464431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042792</td>\n",
       "      <td>0.14</td>\n",
       "      <td>104853812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         class_6  class_15  class_16  class_42  class_52  class_53  class_62  \\\n",
       "2800897      0.0  0.161452       0.0  0.206929  0.011763       0.0  0.043358   \n",
       "\n",
       "         class_64  class_65  class_67  class_88  class_90  class_92  class_95  \\\n",
       "2800897  0.029377       0.0  0.011671  0.028226  0.464431       0.0  0.042792   \n",
       "\n",
       "         class_99  object_id  \n",
       "2800897      0.14  104853812  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_nn[ans_nn.object_id == 104853812]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_6</th>\n",
       "      <th>class_15</th>\n",
       "      <th>class_16</th>\n",
       "      <th>class_42</th>\n",
       "      <th>class_52</th>\n",
       "      <th>class_53</th>\n",
       "      <th>class_62</th>\n",
       "      <th>class_64</th>\n",
       "      <th>class_65</th>\n",
       "      <th>class_67</th>\n",
       "      <th>class_88</th>\n",
       "      <th>class_90</th>\n",
       "      <th>class_92</th>\n",
       "      <th>class_95</th>\n",
       "      <th>class_99</th>\n",
       "      <th>object_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.335980</td>\n",
       "      <td>0.401973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.163074</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.089391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.153496</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134047</td>\n",
       "      <td>0.360678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038923</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012546</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.448948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.147542</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124682</td>\n",
       "      <td>0.205890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074471</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077712</td>\n",
       "      <td>0.002354</td>\n",
       "      <td>0.507249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005080</td>\n",
       "      <td>0.148228</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092321</td>\n",
       "      <td>0.117170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129122</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.282530</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.338650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036312</td>\n",
       "      <td>0.162777</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102304</td>\n",
       "      <td>0.113245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008820</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009943</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.748205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007201</td>\n",
       "      <td>0.098973</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_6  class_15  class_16  class_42  class_52  class_53  class_62  \\\n",
       "0      0.0  0.002284       0.0  0.335980  0.401973       0.0  0.163074   \n",
       "1      0.0  0.003811       0.0  0.134047  0.360678       0.0  0.038923   \n",
       "2      0.0  0.001557       0.0  0.124682  0.205890       0.0  0.074471   \n",
       "3      0.0  0.000705       0.0  0.092321  0.117170       0.0  0.129122   \n",
       "4      0.0  0.010206       0.0  0.102304  0.113245       0.0  0.008820   \n",
       "\n",
       "   class_64  class_65  class_67  class_88  class_90  class_92  class_95  \\\n",
       "0  0.000114       0.0  0.006985  0.000175  0.089391       0.0  0.000024   \n",
       "1  0.000453       0.0  0.012546  0.000143  0.448948       0.0  0.000450   \n",
       "2  0.001003       0.0  0.077712  0.002354  0.507249       0.0  0.005080   \n",
       "3  0.002480       0.0  0.282530  0.000709  0.338650       0.0  0.036312   \n",
       "4  0.000073       0.0  0.009943  0.000003  0.748205       0.0  0.007201   \n",
       "\n",
       "   class_99  object_id  \n",
       "0  0.153496         13  \n",
       "1  0.147542         14  \n",
       "2  0.148228         17  \n",
       "3  0.162777         23  \n",
       "4  0.098973         34  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_nn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_6</th>\n",
       "      <th>class_15</th>\n",
       "      <th>class_16</th>\n",
       "      <th>class_42</th>\n",
       "      <th>class_52</th>\n",
       "      <th>class_53</th>\n",
       "      <th>class_62</th>\n",
       "      <th>class_64</th>\n",
       "      <th>class_65</th>\n",
       "      <th>class_67</th>\n",
       "      <th>class_88</th>\n",
       "      <th>class_90</th>\n",
       "      <th>class_92</th>\n",
       "      <th>class_95</th>\n",
       "      <th>class_99</th>\n",
       "      <th>object_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415095</td>\n",
       "      <td>0.043948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032072</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005241</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.497805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>0.176375</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108876</td>\n",
       "      <td>0.013463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048363</td>\n",
       "      <td>0.004658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012685</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.797219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006232</td>\n",
       "      <td>0.107780</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063914</td>\n",
       "      <td>0.008251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018703</td>\n",
       "      <td>0.002576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014331</td>\n",
       "      <td>0.012107</td>\n",
       "      <td>0.867410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>0.075995</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177923</td>\n",
       "      <td>0.011381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035405</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081573</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.678767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006756</td>\n",
       "      <td>0.149492</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052364</td>\n",
       "      <td>0.058403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009010</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007134</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.868779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>0.075262</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_6  class_15  class_16  class_42  class_52  class_53  class_62  \\\n",
       "0      0.0  0.002536       0.0  0.415095  0.043948       0.0  0.032072   \n",
       "1      0.0  0.005886       0.0  0.108876  0.013463       0.0  0.048363   \n",
       "2      0.0  0.005199       0.0  0.063914  0.008251       0.0  0.018703   \n",
       "3      0.0  0.003614       0.0  0.177923  0.011381       0.0  0.035405   \n",
       "4      0.0  0.002757       0.0  0.052364  0.058403       0.0  0.009010   \n",
       "\n",
       "   class_64  class_65  class_67  class_88  class_90  class_92  class_95  \\\n",
       "0  0.000652       0.0  0.005241  0.000552  0.497805       0.0  0.002099   \n",
       "1  0.004658       0.0  0.012685  0.002619  0.797219       0.0  0.006232   \n",
       "2  0.002576       0.0  0.014331  0.012107  0.867410       0.0  0.007508   \n",
       "3  0.003067       0.0  0.081573  0.001515  0.678767       0.0  0.006756   \n",
       "4  0.000339       0.0  0.007134  0.000275  0.868779       0.0  0.000940   \n",
       "\n",
       "   class_99  object_id  \n",
       "0  0.176375         13  \n",
       "1  0.107780         14  \n",
       "2  0.075995         17  \n",
       "3  0.149492         23  \n",
       "4  0.075262         34  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_lgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 然后两者可以开始merge了\n",
    "\n",
    "ans_nn.sort_values(by='object_id', inplace=True)\n",
    "ans_lgb.sort_values(by='object_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = ans_nn.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class_6',\n",
       " 'class_15',\n",
       " 'class_16',\n",
       " 'class_42',\n",
       " 'class_52',\n",
       " 'class_53',\n",
       " 'class_62',\n",
       " 'class_64',\n",
       " 'class_65',\n",
       " 'class_67',\n",
       " 'class_88',\n",
       " 'class_90',\n",
       " 'class_92',\n",
       " 'class_95',\n",
       " 'class_99']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = sub.columns.tolist()[:-1]\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_nn = 0.8\n",
    "ratio_lgb = 0.2\n",
    "sub[classes] = ratio_nn * ans_nn[classes] + ratio_lgb * ans_lgb[classes] \n",
    "sub.object_id = sub.object_id.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_6</th>\n",
       "      <th>class_15</th>\n",
       "      <th>class_16</th>\n",
       "      <th>class_42</th>\n",
       "      <th>class_52</th>\n",
       "      <th>class_53</th>\n",
       "      <th>class_62</th>\n",
       "      <th>class_64</th>\n",
       "      <th>class_65</th>\n",
       "      <th>class_67</th>\n",
       "      <th>class_88</th>\n",
       "      <th>class_90</th>\n",
       "      <th>class_92</th>\n",
       "      <th>class_95</th>\n",
       "      <th>class_99</th>\n",
       "      <th>object_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.351803</td>\n",
       "      <td>0.330368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136874</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006636</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.171074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.158072</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129013</td>\n",
       "      <td>0.291235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040811</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012574</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.518602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.139590</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112528</td>\n",
       "      <td>0.166362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063317</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065036</td>\n",
       "      <td>0.004305</td>\n",
       "      <td>0.579281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005566</td>\n",
       "      <td>0.133781</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109441</td>\n",
       "      <td>0.096012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110379</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.242339</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.406673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030401</td>\n",
       "      <td>0.160120</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092316</td>\n",
       "      <td>0.102277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008858</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009381</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.772320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005949</td>\n",
       "      <td>0.094231</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_6  class_15  class_16  class_42  class_52  class_53  class_62  \\\n",
       "0      0.0  0.002334       0.0  0.351803  0.330368       0.0  0.136874   \n",
       "1      0.0  0.004226       0.0  0.129013  0.291235       0.0  0.040811   \n",
       "2      0.0  0.002285       0.0  0.112528  0.166362       0.0  0.063317   \n",
       "3      0.0  0.001287       0.0  0.109441  0.096012       0.0  0.110379   \n",
       "4      0.0  0.008716       0.0  0.092316  0.102277       0.0  0.008858   \n",
       "\n",
       "   class_64  class_65  class_67  class_88  class_90  class_92  class_95  \\\n",
       "0  0.000222       0.0  0.006636  0.000250  0.171074       0.0  0.000439   \n",
       "1  0.001294       0.0  0.012574  0.000638  0.518602       0.0  0.001606   \n",
       "2  0.001318       0.0  0.065036  0.004305  0.579281       0.0  0.005566   \n",
       "3  0.002597       0.0  0.242339  0.000870  0.406673       0.0  0.030401   \n",
       "4  0.000126       0.0  0.009381  0.000057  0.772320       0.0  0.005949   \n",
       "\n",
       "   class_99  object_id  \n",
       "0  0.158072         13  \n",
       "1  0.139590         14  \n",
       "2  0.133781         17  \n",
       "3  0.160120         23  \n",
       "4  0.094231         34  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3492890 entries, 0 to 3492889\n",
      "Data columns (total 16 columns):\n",
      "class_6      float64\n",
      "class_15     float64\n",
      "class_16     float64\n",
      "class_42     float64\n",
      "class_52     float64\n",
      "class_53     float64\n",
      "class_62     float64\n",
      "class_64     float64\n",
      "class_65     float64\n",
      "class_67     float64\n",
      "class_88     float64\n",
      "class_90     float64\n",
      "class_92     float64\n",
      "class_95     float64\n",
      "class_99     float64\n",
      "object_id    int32\n",
      "dtypes: float64(15), int32(1)\n",
      "memory usage: 439.7 MB\n"
     ]
    }
   ],
   "source": [
    "sub.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3492890"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.object_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('1101_halfmerge_lgb_nn.gz', index=False, float_format='%.6f', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('1101_merge_lgb_3_nn_7.gz', index=False, float_format='%.6f', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('1101_merge_lgb_2_nn_8.gz', index=False, float_format='%.6f', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
